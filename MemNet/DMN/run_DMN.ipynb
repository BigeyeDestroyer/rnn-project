{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Python code written by Dong-Sig Han. 2016-01 ~ 2016-02\n",
    "import sys\n",
    "from glob import glob\n",
    "from parseBabiTask import *\n",
    "from DMN import DMN\n",
    "import time\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T \n",
    "import lasagne\n",
    "from itertools import chain\n",
    "from lasagne.regularization import regularize_layer_params, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load training datasets.\n",
    "base_dir = 'tasks_1-20_v1-2/en/'\n",
    "train_data_path = [glob(base_dir + 'qa' + str(t) + '_*_train.txt')[0] for t in xrange(1, 21)]\n",
    "word_dict = dict(nil = 0)\n",
    "story, questions, qstory = parseBabiTask(train_data_path, word_dict, 11, 228, False)\n",
    "\n",
    "# load testing datasets.\n",
    "test_data_path = [glob(base_dir + 'qa' + str(t) + '_*_test.txt')[0] for t in xrange(1, 21)]\n",
    "test_story, test_questions, test_qstory = parseBabiTask(test_data_path, word_dict, 11, 228, False)\n",
    "\n",
    "# get an inverted dictionary that keys and values have been switched\n",
    "# e.g. word_dict['Mary'] -> 0; inv_word_dict[0] -> 'Mary'\n",
    "inv_word_dict = {v: k for k, v in word_dict.items()}\n",
    "\n",
    "def get_word_size(sentence):\n",
    "    return np.count_nonzero(sentence)\n",
    "\n",
    "# get word size of each sentence of inputs and questions\n",
    "story_word       = np.zeros(story.shape[0:2],       np.int32)\n",
    "qstory_word      = np.zeros(qstory.shape[0:1],      np.int32)\n",
    "test_story_word  = np.zeros(test_story.shape[0:2],  np.int32)\n",
    "test_qstory_word = np.zeros(test_qstory.shape[0:1], np.int32)\n",
    "\n",
    "for i in xrange(story_word.shape[0]):\n",
    "    for j in xrange(story_word.shape[1]):\n",
    "        story_word[i, j]= get_word_size(story[i, j])\n",
    "for i in xrange(qstory_word.shape[0]):\n",
    "    qstory_word[i]= get_word_size(qstory[i])\n",
    "for i in xrange(test_story_word.shape[0]):\n",
    "    for j in xrange(test_story_word.shape[1]):\n",
    "        test_story_word[i, j]= get_word_size(test_story[i, j])\n",
    "for i in xrange(test_qstory_word.shape[0]):\n",
    "    test_qstory_word[i]= get_word_size(test_qstory[i])\n",
    "\n",
    "\n",
    "task       = range(1,21) # load all.\n",
    "#task        = [20]#, 2, 3]#, 3]#, 3,7, 8] # load certain tasks.\n",
    "train_size  = int(questions.shape[0]*0.05*len(task))\n",
    "ordered     = np.concatenate([np.arange(1000*(t-1), 1000*t, dtype=np.int32) for t in task], axis=0) \n",
    "rp          = np.random.permutation(ordered)\n",
    "train_range = rp[0:int(1.0 * train_size)]\n",
    "# RECENTLY, I DO NOT USE VALIDATION SET BECAUSE IT IS USELESS IN EPISODIC QA PROBLEMS.\n",
    "val_range   = rp[int(0.95 * train_size):train_size] \n",
    "test_size   = train_size\n",
    "\n",
    "# function for laoding batch data\n",
    "def batch_inputs_and_outputs(batch_start, batch_end,\n",
    "                             story, questions, qstory,\n",
    "                             story_word, qstory_word,\n",
    "                             arr=ordered, time_noise=False, ep_pass=3, max_sentence=50, mapping=None):\n",
    "    story_ind     = questions[arr[batch_start:batch_end],0]\n",
    "    sentence_ind  = questions[arr[batch_start:batch_end],1]\n",
    "    target_answer = questions[arr[batch_start:batch_end],2]\n",
    "    \n",
    "    input_sentence = sentence_ind+1\n",
    "   \n",
    "    input_sentence_generalized = np.minimum(input_sentence, max_sentence)\n",
    "    input_sentence_cutoff = input_sentence - input_sentence_generalized \n",
    "    \n",
    "    batch_max_sentence = np.max(input_sentence_generalized)\n",
    "    input_word     = np.zeros((batch_end-batch_start,batch_max_sentence), dtype=np.int32)\n",
    "    \n",
    "    for i in xrange(len(input_word)):\n",
    "        c = input_sentence_cutoff[i]\n",
    "        input_word[i] = np.pad(story_word[story_ind[i], c:(c+input_sentence_generalized[i])],\n",
    "                               (0,batch_max_sentence-input_sentence_generalized[i]),\n",
    "                               mode='constant',\n",
    "                               constant_values=0)\n",
    "    \n",
    "    batch_max_word = np.max(input_word)\n",
    "    input = np.zeros((batch_end-batch_start,batch_max_sentence,batch_max_word), dtype=np.int32)\n",
    "    for i in xrange(len(input)):\n",
    "        c = input_sentence_cutoff[i]\n",
    "        input[i] = np.pad(story[story_ind[i], c:(c+input_sentence_generalized[i]), :batch_max_word],\n",
    "                          ((0,batch_max_sentence-input_sentence_generalized[i]),(0,0)),\n",
    "                          mode='constant',\n",
    "                          constant_values=0)\n",
    "    '''\n",
    "    batch_max_sentence = np.max(input_sentence)\n",
    "    input_word     = story_word[story_ind,:batch_max_sentence]\n",
    "    input          = story[story_ind,:batch_max_sentence,:np.max(input_word)]\n",
    "    '''\n",
    "    if time_noise:\n",
    "        time_sequence = np.arange(int(batch_max_sentence * 1.2),dtype=np.int32)\n",
    "        np.random.shuffle(time_sequence)\n",
    "        input_time = np.sort(time_sequence[:batch_max_sentence])[::-1]\n",
    "    else:\n",
    "        input_time = np.arange(batch_max_sentence,dtype=np.int32)[::-1] \n",
    "    \n",
    "    question_word = np.reshape(qstory_word[arr[batch_start:batch_end]],\n",
    "                               (batch_end-batch_start, 1))\n",
    "    question      = np.reshape(qstory[arr[batch_start:batch_end],:np.max(question_word)],\n",
    "                               (batch_end-batch_start, 1, np.max(question_word)))\n",
    "     \n",
    "    gate_supervision = questions[arr[batch_start:batch_end],3:3+ep_pass].copy()\n",
    "    \n",
    "    for i in xrange(gate_supervision.shape[0]):\n",
    "        for j in xrange(gate_supervision.shape[1]):\n",
    "            if gate_supervision[i,j] < 0:\n",
    "                #gate_supervision[i,j] = np.random.randint(batch_max_sentence)\n",
    "                gate_supervision[i,j] = gate_supervision[i,j-1]\n",
    "\n",
    "    gate_supervision = (gate_supervision - input_sentence_cutoff.reshape(-1,1)).reshape(-1)\n",
    "            \n",
    "    for i in xrange(len(gate_supervision)):\n",
    "        if gate_supervision[i] < 0:\n",
    "            gate_supervision[i] = np.random.randint(batch_max_sentence)\n",
    "    \n",
    "    if mapping is None:\n",
    "        return (input, input_sentence_generalized, input_word, input_time,\n",
    "            question, question_word,\n",
    "            target_answer, gate_supervision)\n",
    "    else:\n",
    "        return (mapping[input], input_sentence_generalized, input_word, input_time,\n",
    "            mapping[question], question_word,\n",
    "            mapping[target_answer], gate_supervision)\n",
    "\n",
    "def single_input_and_output(idx, story, questions, qstory,\n",
    "                            story_word, qstory_word,\n",
    "                            arr=ordered, time_noise=False, ep_pass=3, mapping=None):\n",
    "    return batch_inputs_and_outputs(idx,idx+1,story,questions,qstory,\n",
    "                                    story_word,qstory_word,arr,time_noise, ep_pass, mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_person_word = ['jason', 'antoine', 'brian', 'fred', 'daniel', 'bernhard', 'jeff', 'julius', 'john', 'greg']\n",
    "female_person_word = ['emily', 'jessica', 'winona', 'julie', 'mary', 'lily', 'sandra']\n",
    "get_word    = ['picked', 'received', 'grabbed']\n",
    "put_word    = ['left', 'dropped', 'put down', 'discarded']\n",
    "go_word     = ['went', 'moved', 'journeyed', 'travelled']\n",
    "place_word  = ['office', 'bedroom', 'bathroom', 'kitchen', 'hallway', 'garden']\n",
    "\n",
    "def switch_mapping(current_mapping, word_dict, word_class):\n",
    "    idx = [word_dict[word] for word in word_class]\n",
    "    idx_shuffled = np.random.permutation(idx)\n",
    "    for i in xrange(len(idx)):\n",
    "        current_mapping[idx[i]] = idx_shuffled[i]\n",
    "    return current_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'nil' was not found in GloVe. Replacing its embedding with a radom vector\n"
     ]
    }
   ],
   "source": [
    "#configuration\n",
    "config = dict()\n",
    "config['max_word']        = story.shape[2]\n",
    "config['max_sentence']    = story.shape[1]\n",
    "config['max_answer_word'] = 1\n",
    "config['voc_size']        = len(word_dict)\n",
    "config['hid_state_size']  = 300\n",
    "config['max_gate_supervision'] = np.max(map(lambda x: np.sum(x >= 0), questions[:,3:14]))\n",
    "config['ep_pass']         = 3\n",
    "\n",
    "#use glove vectors\n",
    "config['pretrained_word_embedding'] = True\n",
    "glove_words = []\n",
    "glove_vectors = []\n",
    "filename = \"glove.6B.bAbI.txt\"\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split(' ')\n",
    "        glove_words.append(l[0])\n",
    "        glove_vectors.append(np.asarray(map(np.float32, l[1:]), dtype=theano.config.floatX))\n",
    "glove = dict(zip(glove_words, glove_vectors))\n",
    "\n",
    "word_embedding_matrix = np.zeros((len(word_dict), config['hid_state_size']), dtype=np.float32)\n",
    "\n",
    "for i in xrange(len(word_dict)):\n",
    "    words = inv_word_dict[i].split(',')\n",
    "    for j in xrange(len(words)):\n",
    "        if   words[j] == 'n':\n",
    "            word_embedding_matrix[i,:] += glove['north']\n",
    "        elif words[j] == 's':\n",
    "            word_embedding_matrix[i,:] += glove['south']\n",
    "        elif words[j] == 'e':\n",
    "            word_embedding_matrix[i,:] += glove['east']\n",
    "        elif words[j] == 'w':\n",
    "            word_embedding_matrix[i,:] += glove['west']\n",
    "        elif glove.has_key(words[j]):\n",
    "            word_embedding_matrix[i,:] += glove[words[j]]\n",
    "        else :\n",
    "            word_embedding_matrix[i,:] += np.random.normal(0, 0.2, 300).astype(np.float32)\n",
    "            print ('Word \\'' + words[j] + '\\' was not found in GloVe. Replacing its embedding with a radom vector')\n",
    "# It will be used in Initialization of Semantic Memory Module\n",
    "config['word_embedding'] = word_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmn = DMN(config, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile prediction and gate_activation\n",
    "prediction = T.reshape(lasagne.layers.get_output(dmn.A), (-1, config['voc_size']))\n",
    "gate_activation = lasagne.layers.get_output(dmn.E_G)\n",
    "predict_fn = theano.function([dmn.input_var, dmn.input_sentence_var, dmn.input_word_var, dmn.input_time_var,\n",
    "                              dmn.question_var, dmn.question_word_var,\n",
    "                              dmn.word_dropout_var, dmn.epmem_dropout_var], prediction)\n",
    "gate_fn = theano.function([dmn.input_var, dmn.input_sentence_var,  dmn.input_word_var, dmn.input_time_var,\n",
    "                           dmn.question_var, dmn.question_word_var,\n",
    "                           dmn.word_dropout_var], gate_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: john took the football there .\n",
      "1: john left the football .\n",
      "2: mary went back to the bathroom .\n",
      "3: sandra got the football there .\n",
      "4: daniel journeyed to the kitchen .\n",
      "5: john journeyed to the bedroom .\n",
      "6: sandra dropped the football .\n",
      "7: mary moved to the kitchen .\n",
      "8: daniel grabbed the apple there .\n",
      "9: mary went to the bathroom .\n",
      "10: mary moved to the bedroom .\n",
      "11: john went back to the bathroom .\n",
      "12: daniel discarded the apple there .\n",
      "13: mary travelled to the kitchen .\n",
      "14: sandra picked up the football there .\n",
      "15: sandra left the football there .\n",
      "16: mary went to the hallway .\n",
      "17: daniel got the apple there .\n",
      "18: daniel travelled to the hallway .\n",
      "19: mary took the football there .\n",
      "20: john travelled to the hallway .\n",
      "21: mary put down the football .\n",
      "22: mary went back to the bedroom .\n",
      "23: john went back to the office .\n",
      "where is the football ?\n",
      "=======================================\n",
      "The model predicted 'wolf', where the target is 'hallway'\n"
     ]
    }
   ],
   "source": [
    "# An example question in test set \n",
    "input, i_s, i_w, i_t, q, q_w, t, g_s = single_input_and_output(1999, test_story, test_questions, test_qstory,\n",
    "                                                               test_story_word, test_qstory_word, time_noise=False,\n",
    "                                                               ep_pass=config['ep_pass'])\n",
    "cnt = -1\n",
    "for j in xrange(i_s[0]):\n",
    "    cnt += 1\n",
    "    print str(cnt)+':',\n",
    "    for k in xrange(i_w[0,j]):\n",
    "        print inv_word_dict[input[0,j,k]],\n",
    "    print('.')\n",
    "for i in xrange(q_w[0,0]):\n",
    "    print inv_word_dict[q[0,0,i]],\n",
    "print('?')\n",
    "\n",
    "answer = predict_fn(input, i_s, i_w, i_t, q, q_w, 0, 0)\n",
    "print('=======================================')\n",
    "print('The model predicted \\''+inv_word_dict[np.argmax(answer)] + '\\', where the target is \\'' + inv_word_dict[t[0]] + '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define loss and compile traing and valdidation functions.\n",
    "\n",
    "# Cross Entropy error of prediction.\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, dmn.target_answer_var)\n",
    "\n",
    "# Cross Entropy error of gate activation.\n",
    "loss_gate = lasagne.objectives.categorical_crossentropy(gate_activation, dmn.target_gate_var)\n",
    "loss_pretrain = loss_gate.mean()\n",
    "\n",
    "# Training : Train the model by prediction and gate activation.\n",
    "loss = loss.mean() #+ loss_pretrain #+ (regularize_layer_params(layers, l2) * 1e-5)\n",
    "loss2= loss+loss_pretrain \n",
    "layers = [dmn.S] + lasagne.layers.get_all_layers(dmn.A)\n",
    "params = chain.from_iterable(l.get_params(trainable=True) for l in layers)\n",
    "params = lasagne.utils.unique(params)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=0.0001)\n",
    "updates2 = lasagne.updates.adam(loss2, params, learning_rate=0.0001)\n",
    "\n",
    "\n",
    "# Pratraining : Only train by gate activation.\n",
    "layers_pretrain = [dmn.S] + lasagne.layers.get_all_layers(dmn.E_G)\n",
    "params_pretrain = chain.from_iterable(l.get_params(trainable=True) for l in layers_pretrain)\n",
    "params_pretrain = lasagne.utils.unique(params_pretrain)\n",
    "updates_pretrain = lasagne.updates.adam(loss_pretrain, params_pretrain, learning_rate=0.0015)\n",
    "\n",
    "# Validation : Pre-evaluate the model by its prediction derived by 5% of TEST SET \n",
    "test_prediction =  T.reshape(lasagne.layers.get_output(dmn.A, deterministic=True), (-1, config['voc_size']))\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, dmn.target_answer_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), dmn.target_answer_var), dtype=theano.config.floatX)\n",
    "\n",
    "pre_train_fn = theano.function([dmn.input_var,\n",
    "                                dmn.input_sentence_var,\n",
    "                                dmn.input_word_var,\n",
    "                                dmn.input_time_var,\n",
    "                                dmn.question_var,\n",
    "                                dmn.question_word_var,\n",
    "                                dmn.target_gate_var,\n",
    "                                dmn.word_dropout_var],\n",
    "                               loss_pretrain,\n",
    "                               updates=updates_pretrain)\n",
    "\n",
    "gate_val_fn = theano.function([dmn.input_var,\n",
    "                          dmn.input_sentence_var,\n",
    "                          dmn.input_word_var,\n",
    "                          dmn.input_time_var,\n",
    "                          dmn.question_var,\n",
    "                          dmn.question_word_var,\n",
    "                          dmn.target_answer_var,\n",
    "                          dmn.target_gate_var,\n",
    "                          dmn.word_dropout_var,\n",
    "                          dmn.epmem_dropout_var],\n",
    "                         [loss_pretrain, test_acc])\n",
    "\n",
    "train_fn = theano.function([dmn.input_var,\n",
    "                            dmn.input_sentence_var,\n",
    "                            dmn.input_word_var,\n",
    "                            dmn.input_time_var,\n",
    "                            dmn.question_var,\n",
    "                            dmn.question_word_var,\n",
    "                            dmn.target_answer_var,\n",
    "                            dmn.word_dropout_var,\n",
    "                            dmn.epmem_dropout_var],\n",
    "                           loss,\n",
    "                           updates=updates)\n",
    "\n",
    "train_with_gate_fn = theano.function([dmn.input_var,\n",
    "                            dmn.input_sentence_var,\n",
    "                            dmn.input_word_var,\n",
    "                            dmn.input_time_var,\n",
    "                            dmn.question_var,\n",
    "                            dmn.question_word_var,\n",
    "                            dmn.target_answer_var,\n",
    "                            dmn.target_gate_var,\n",
    "                            dmn.word_dropout_var,\n",
    "                            dmn.epmem_dropout_var],\n",
    "                           loss2,\n",
    "                           updates=updates2)\n",
    "\n",
    "val_fn = theano.function([dmn.input_var,\n",
    "                          dmn.input_sentence_var,\n",
    "                          dmn.input_word_var,\n",
    "                          dmn.input_time_var,\n",
    "                          dmn.question_var,\n",
    "                          dmn.question_word_var,\n",
    "                          dmn.target_answer_var,\n",
    "                          dmn.word_dropout_var,\n",
    "                          dmn.epmem_dropout_var],\n",
    "                         [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We iterate over epochs:\n",
    "num_epochs=5\n",
    "epoch_pretraining=0\n",
    "\n",
    "batch_size=50\n",
    "n_train_batch=int(len(train_range)/batch_size)\n",
    "n_valid_batch=int(len(val_range)/batch_size)\n",
    "ep_pass = config['ep_pass']\n",
    "\n",
    "print(\"Starting training... (1~{} epoch: pretraining)\".format(epoch_pretraining))\n",
    "\n",
    "file_load_mode = True\n",
    "file_save_mode = True\n",
    "fname          = \"dmn_trained\"\n",
    "\n",
    "if file_load_mode:\n",
    "    dmn.load_params(fname)\n",
    "    print (\"loaded\")\n",
    "\n",
    "vocabulary_shuffling = False\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    np.random.shuffle(train_range)\n",
    "    \n",
    "    if vocabulary_shuffling:\n",
    "        switched_mapping = None\n",
    "    else:\n",
    "        switched_mapping = switch_mapping(    \n",
    "        switch_mapping(\n",
    "            switch_mapping(\n",
    "                np.arange(len(word_dict), dtype=np.int32), \n",
    "                word_dict, \n",
    "                female_person_word),\n",
    "            word_dict, \n",
    "        male_person_word),\n",
    "        word_dict, place_word)\n",
    "    \n",
    "    for batch in xrange(n_train_batch):\n",
    "        i,i_s,i_w,i_t,q,q_w,t,g_s = batch_inputs_and_outputs(batch*batch_size, (batch+1)*batch_size,\n",
    "                                                             story, questions, qstory,\n",
    "                                                             story_word, qstory_word,\n",
    "                                                             train_range, True, ep_pass, mapping=switched_mapping)\n",
    "        if epoch < epoch_pretraining:\n",
    "            train_err += pre_train_fn(i,i_s,i_w,i_t,q,q_w,g_s,0.01)\n",
    "        else:\n",
    "            #train_err += train_with_gate_fn(i,i_s,i_w,i_t,q,q_w,t,g_s,0.01,0.01)\n",
    "            train_err += train_fn(i,i_s,i_w,i_t,q,q_w,t,0.01,0.5)\n",
    "                                            \n",
    "        train_batches += 1        \n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "\n",
    "    for batch in xrange(n_valid_batch):\n",
    "        i,i_s,i_w,i_t,q,q_w,t,g_s = batch_inputs_and_outputs(batch*batch_size, (batch+1)*batch_size,\n",
    "                                                             test_story, test_questions, test_qstory,\n",
    "                                                             test_story_word, test_qstory_word,\n",
    "                                                             val_range, False,ep_pass)\n",
    "        if epoch < epoch_pretraining:\n",
    "            err, acc = gate_val_fn(i,i_s,i_w,i_t,q,q_w,t,g_s,0,0)\n",
    "        else:\n",
    "            err, acc = val_fn(i,i_s,i_w,i_t,q,q_w,t,0,0)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    \n",
    "    # Then we print the results for every five epoch:\n",
    "    #if epoch % 5 == 4:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  train loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  val loss & accuracy:\\t{:.6f} ({:.2f} %)\".format(val_err / val_batches, val_acc / val_batches * 100))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Save the state of DMN\n",
    "    if (epoch >= epoch_pretraining and file_save_mode):\n",
    "        dmn.save_params(fname)\n",
    "if file_save_mode:\n",
    "    dmn.save_params(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "Task 1:\n",
      "  test loss:\t\t\t0.039496\n",
      "  test accuracy:\t\t98.60 %\n",
      "Task 2:\n",
      "  test loss:\t\t\t0.555687\n",
      "  test accuracy:\t\t78.60 %\n",
      "Task 3:\n",
      "  test loss:\t\t\t0.495852\n",
      "  test accuracy:\t\t84.20 %\n",
      "Task 4:\n",
      "  test loss:\t\t\t0.080299\n",
      "  test accuracy:\t\t97.50 %\n",
      "Task 5:\n",
      "  test loss:\t\t\t0.069978\n",
      "  test accuracy:\t\t98.90 %\n",
      "Task 6:\n",
      "  test loss:\t\t\t0.018932\n",
      "  test accuracy:\t\t99.20 %\n",
      "Task 7:\n",
      "  test loss:\t\t\t0.519839\n",
      "  test accuracy:\t\t87.40 %\n",
      "Task 8:\n",
      "  test loss:\t\t\t0.211579\n",
      "  test accuracy:\t\t95.30 %\n",
      "Task 9:\n",
      "  test loss:\t\t\t0.076210\n",
      "  test accuracy:\t\t98.00 %\n",
      "Task 10:\n",
      "  test loss:\t\t\t0.221696\n",
      "  test accuracy:\t\t95.40 %\n",
      "Task 11:\n",
      "  test loss:\t\t\t0.861879\n",
      "  test accuracy:\t\t85.30 %\n",
      "Task 12:\n",
      "  test loss:\t\t\t0.114424\n",
      "  test accuracy:\t\t96.00 %\n",
      "Task 13:\n",
      "  test loss:\t\t\t0.371519\n",
      "  test accuracy:\t\t92.40 %\n",
      "Task 14:\n",
      "  test loss:\t\t\t0.048772\n",
      "  test accuracy:\t\t98.30 %\n",
      "Task 15:\n",
      "  test loss:\t\t\t0.070488\n",
      "  test accuracy:\t\t98.20 %\n",
      "Task 16:\n",
      "  test loss:\t\t\t1.694788\n",
      "  test accuracy:\t\t65.90 %\n",
      "Task 17:\n",
      "  test loss:\t\t\t1.799691\n",
      "  test accuracy:\t\t63.00 %\n",
      "Task 18:\n",
      "  test loss:\t\t\t0.124499\n",
      "  test accuracy:\t\t96.60 %\n",
      "Task 19:\n",
      "  test loss:\t\t\t2.148067\n",
      "  test accuracy:\t\t45.60 %\n",
      "Task 20:\n",
      "  test loss:\t\t\t0.020180\n",
      "  test accuracy:\t\t99.30 %\n",
      "88.6850000098\n"
     ]
    }
   ],
   "source": [
    "# After training, we compute and print the test error:\n",
    "fname          = \"dmn_trained\"\n",
    "file_load_mode = True\n",
    "\n",
    "if file_load_mode:\n",
    "    dmn.load_params(fname)\n",
    "    print (\"loaded\")\n",
    "\n",
    "batch_size = 50\n",
    "ep_pass = config['ep_pass']\n",
    "\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "n_test_batch=int(test_size/batch_size)\n",
    "\n",
    "tsk_b = 0\n",
    "\n",
    "tmp = 0.\n",
    "\n",
    "for tsk in task:\n",
    "    tsk_b += 1\n",
    "    test_err = 0\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    \n",
    "    for batch in xrange(int(n_test_batch/len(task))):\n",
    "        i, i_s, i_w, i_t, q, q_w, t, g_s = batch_inputs_and_outputs(1000*(tsk_b-1)+batch*batch_size, \n",
    "                                                                    1000*(tsk_b-1)+(batch+1)*batch_size, \n",
    "                                                                    test_story, test_questions, test_qstory, \n",
    "                                                                    test_story_word, test_qstory_word, \n",
    "                                                                    ep_pass=ep_pass)\n",
    "\n",
    "        err, acc = val_fn(i, i_s, i_w, i_t, q, q_w, t, 0, 0)\n",
    "        test_err += err\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "\n",
    "    print(\"Task {}:\".format(tsk))\n",
    "    print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "    tmp += (test_acc / test_batches * 100)\n",
    "print(tmp/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: julie picked up the apple .\n",
      "1: sandra went back to the bedroom .\n",
      "2: julie discarded the football there .\n",
      "3: julie went to the garden .\n",
      "4: julie dropped the apple .\n",
      "5: julie picked up the apple .\n",
      "6: antoine moved to the office .\n",
      "7: antoine moved to the hallway .\n",
      "8: julie dropped the apple .\n",
      "9: julie took the apple .\n",
      "10: julie travelled to the kitchen .\n",
      "11: julie journeyed to the garden .\n",
      "12: sandra journeyed to the hallway .\n",
      "13: julie dropped the apple .\n",
      "14: julie grabbed the apple .\n",
      "15: brian moved to the bedroom .\n",
      "16: julie put down the apple .\n",
      "17: sandra moved to the kitchen .\n",
      "18: brian grabbed the milk there .\n",
      "19: julie got the apple .\n",
      "20: brian left the milk .\n",
      "21: antoine went back to the bathroom .\n",
      "22: antoine went back to the office .\n",
      "23: julie travelled to the kitchen .\n",
      "24: brian moved to the garden .\n",
      "25: sandra went back to the bathroom .\n",
      "26: brian moved to the bedroom .\n",
      "27: julie went to the bathroom .\n",
      "28: sandra moved to the garden .\n",
      "29: julie went back to the bedroom .\n",
      "30: julie picked up the milk .\n",
      "31: julie went to the bathroom .\n",
      "32: julie moved to the bedroom .\n",
      "33: sandra moved to the office .\n",
      "34: julie left the milk .\n",
      "35: julie got the milk .\n",
      "36: sandra journeyed to the bathroom .\n",
      "37: julie went back to the kitchen .\n",
      "38: antoine journeyed to the garden .\n",
      "39: sandra grabbed the football there .\n",
      "40: julie left the milk .\n",
      "41: antoine went back to the bedroom .\n",
      "42: sandra journeyed to the hallway .\n",
      "43: antoine went to the kitchen .\n",
      "44: sandra went to the office .\n",
      "45: julie grabbed the milk there .\n",
      "46: sandra put down the football .\n",
      "47: julie put down the apple .\n",
      "48: antoine travelled to the hallway .\n",
      "49: julie got the apple there .\n",
      "where was the football before the office ?\n",
      "=======================================\n",
      "The model predicted 'hallway', where the target is 'hallway'\n"
     ]
    }
   ],
   "source": [
    "switched_mapping = switch_mapping(    \n",
    "    switch_mapping(\n",
    "        switch_mapping(\n",
    "            np.arange(len(word_dict), dtype=np.int32), \n",
    "            word_dict, \n",
    "            female_person_word),\n",
    "        word_dict, \n",
    "    male_person_word),\n",
    "    word_dict, place_word)\n",
    "    \n",
    "\n",
    "# An example question in test set \n",
    "input, i_s, i_w, i_t, q, q_w, t, g_s = single_input_and_output(2999, test_story, test_questions, test_qstory,\n",
    "                                                               test_story_word, test_qstory_word, time_noise=False,\n",
    "                                                               ep_pass=config['ep_pass'], mapping=switched_mapping)\n",
    "cnt = -1\n",
    "for j in xrange(i_s[0]):\n",
    "    cnt += 1\n",
    "    print str(cnt)+':',\n",
    "    for k in xrange(i_w[0,j]):\n",
    "        print inv_word_dict[input[0,j,k]],\n",
    "    print('.')    \n",
    "for i in xrange(q_w[0,0]):\n",
    "    print inv_word_dict[q[0,0,i]],\n",
    "print('?')\n",
    "\n",
    "answer = predict_fn(input, i_s, i_w, i_t, q, q_w, 0, 0)\n",
    "print('=======================================')\n",
    "print('The model predicted \\''+inv_word_dict[np.argmax(answer)] + '\\', where the target is \\'' + inv_word_dict[t[0]] + '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 44, 42], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYFNW57/HvMIwodxHlNigG0WASvOABRdFR0EC2UZ/o\njspB8RLNc7ZKYjyJl51swFsSc9Ekuo3GSxJ3tponJqg7KspRYqJyE0bFC8KIBgbkqghyHabPH2+V\nVdPTPVU9U91V3fX7PE89Xd1dM7NYDC+r33rXWiAiIiIiIiIiIiIiIiIiIiIiIiIiUhYmAO8Ay4Br\nc7z/f4HFzvEG0AT0LlnrREQktGpgOTAEqAHqgeFtXH86MLv4zRIRkVw6Bbw/Cgvq7wO7gUeAM9u4\nfhLwcCQtExGRggUF9UHASt/zVc5ruXQFvgw8FkG7RESkHYKCeqaA7/VV4B/Ax+1vjoiIdETngPcb\ngcG+54Ox0Xou59FG6mXo0KGZhoaGwlonIiINwCFRfbPOzjccAuxF/hulvYCNwD5tfK+MmGnTpsXd\nhMRQX3jUFx71hYfCMiaBI/Um4EpgFlYJcz/wNvBN5/17nMeznGu2F/LDRUQkWkFBHeBp5/C7J+v5\n75xDRERiFHSjVIqgrq4u7iYkhvrCo77wqC/aryrENROAO7D0y33Aj3NcUwfcjk1Q2uA8z+akh0RE\novXii/DnP8Mdd8TdkuhVVVVBuFgNBKdfqoE7gfFYJcwC4Aksr+7qDdyF1aivAvqGb66ISMfV18PL\nL8fdimSIYkbpJGzCkVvquCHC9omIBFq50g6JZkbpMKAP8AKwELggstaJiISwciWsXQu7dsXdkvgF\npV/CJMFrgKOBcdhSAa8Ac7FVHVuYPn36Z+d1dXW6GSIikVi5EjIZaGyEgw+OuzUdM2fOHObMmdPu\nrw9Kvh8LTMdulgJcDzTT8mbptdiko+nO8/uAZ4A/ZX0v3SgVkaI46CDYvRsefRTGjo27NdEq9EZp\nUPplIZZeGYLNKD0Xu1Hq9zhwAnZTtSswGngrbANERDpizx5YswaOPVZ5dYhmRuk72Mj8dWwU/xsU\n1EWkRD78EPr0gaFDFdQhuhmlP3UOEZGSWrkSBg+24913425N/MLMKA3azq4O2Iy3pd33o2qciEiQ\nVaugttaOVfnWkE2RKCYfAfwNOCPy1omIBPCP1JV+iW47u9B3ZkVEoqSg3lIUk48ywBjgNeAp4PDI\nWiciEsAN6gccAJs3w44dcbcoXlFMPlqE7Yi0DZgIzAQOzXWhJh+JSNRWrbKg3qkTDBxozw+JbJ+g\n0kvC5KNsK4CRwKas1zX5SEQiV1sLL71kE5BOPBFuvBEqabwYx+Sjfr4fOMo5zw7oIiKRa2qCdets\nhA7Kq0M0k4/OAf6Pc+02bANqEZGiW70a9t8famrsuYJ6NJOP7nIOEZGScvPprtpaePPN+NqTBFFM\nPnL9L2y0/rUI2iUiEmjlSgvkrsGDNQEpKKi7k48mYKWK5wPD81z3Y2wNGNWsi0hJuOWMLqVfopt8\ndBW21O76KBsnItIWBfXWoph8NAgL9Hc7z1W3KCIlkZ1T79sXPv0Utm2Lr01xCwrqYQL0HcB1zrVV\nKP0iIiWSnVOvqtLCXkHVL43YbFHXYLwNpl0jsbQMQF9sVuluWteza0apiEQqO/0CXgrm0Jzz2pOv\n2DNKOwNLsf1HVwPzsZul2as0uh4EngT+nOM9zSgVkcjs2gXdu8P27VBd7b1+4YVwyilw0UWxNS1S\nhc4ojWLykYhIyTU2Qv/+LQM6WPolzTdLo9r5yHVxx5ojIhKOuzlGtsGDob6+9O1JijCTj0REEidX\nPh1U1hjFjNIzsbXUFwOvAqdE1joRkTwU1HOLYju72cDjzvmXgL8AZbyasYiUg5UrYdiw1q+nPace\nxYzST33n3YENUTVORCSf7IlHrj59rDJmy5bStykJophRCnAWNnp/GpgaTdNERPLLnnjkqqpK98Je\nUWxnB7aF3UxgLPAQcFiuizT5SESiki+nDl5efXiu5QcTLonb2TVgaZuNWa9r8pGIRGLHDujVyyYe\ndcqRb7joIhg7Fi69tORNi1wc29kN9f3Ao53H7IAuIhKZxkbbwi5XQAelX9oSZkbp2cCF2I3UrWg7\nO5GKs3w5ZDK5q03ikC+f7ho8GObPL117kiSKGaW3OYeIVKgZM2DPHvjv/467JaatfDrYe489Vrr2\nJEnYGaVBE5D+NzYB6XXgJWBEJK0Tkdg1N8Nzz8Gzz1pgT4KgoJ7mWvUwQT3MlnbvASdiwfwm4N4I\n2ygiMXr9dejZ0xbPWrgw7taYfDXqrjTn1MME9TATkF4BNjvn84A2sl0iUk5mzYIvfxkmToSnsxOx\nMQnKqffqZfcANm/Of02lChPUw05Acl0KPNWRRolIcrhBfcKEZAX1tkbq7gSkNKZgwtwoLaS4/GTg\nEuD4XG9q8pFIedm6FRYsgLo6qKmBd96BDRtsL9A4BQV18PLqX/xiadoUlWJPPoLwE5BGYDseTcDS\nNdk0+UikzPzP/8DPfgYvvGDPzzwTzj0XJk2Kr03bttn6Ltu324g8n0svhdGj4fLLS9e2Yoh68hGE\nm4B0IBbQJ5M7oItIGXJTL64k5NVXrYJBg9oO6JDem6Vhgrp/AtJbwKN4E5DcSUj/AewL3I2tq57S\nsn+RypId1CdMsNeam+NrU5jUCyinHiRoAtI3nENEKsSKFVY9csQR3mtDhsB++8GiRXDMMfG0K2xQ\nT2utelSTjz6PlTXuAK6JpmkiEqdZs+C001qvrxJ3CiaoRt2V1pF6VJOPNgJXAT+NtHUiEpvs1Isr\n7qBeSPpl1SqrV0+TqCYfrcduqO6OsnEiEo/du63i5bTTWr83diwsWQKbNpW+XRA88cjVo4eVYX70\nUfHblCTFmHwkImVu3jz43OfggANav7f33nDiibYeTBzCjtQhnXn1MEE9ZR9eRCRf6sUVZwombE4d\n0plXD1P90gj4u3AwNlovmGaUipSHWbPgx23sbzZxItx0k5U25tuoohi2boWdO23yURjlWKteihml\nnYGlwDhgNVaDfj5Wq55tOrAF+FmO9zSjVKQMbNhgqZcNG2CvvfJfd+ih8OijcNRRpWvb22/brNZ3\n3w13/U032dZ3t9xS3HYVUzFmlIaZfNQfy7tfDXwf+CfQPWwjRCQ5Zs+Gk05qO6BDPCmYQvLpoJx6\nW54GDgMOAX7ovHYP3gSkD7G0TC9sZumB2NZ2IlJmgvLprjiCeiH5dEhnTr2E2TARSbpMxnY4ChPU\nTzoJ6uvh44+L3y5XoSP1csypd1SYoB40mxTgl877rwElzLCVp47cBKk0ldYXS5bAD38I779f+Ncm\noS+WLIEuXeCQQ4Kv3WcfOOEES9dELV9fhK1Rd9XWpm8CUlBQDzOb9CtYWmYYcDm2qJe0IQn/eJMi\nrr7IZODll+Eb37C1TaZNg4aG9n+/BQvgrLPg1FNh2TIYORIuucTOw0rC74WbeglaAdFVrBRMW0G9\nkJF6t272n8+GDdG0qxwEBfUws0nPAH7nnM8DegP9omuiSHQ+/BB+8hM4/HC4+GKr4LjzTlu46rjj\nbFLN/ffDJ5+E+34vvmizLs8+G8aNg/fegwcegOXLbfGrMWNs7fElS4r6x4pM2Hy6a+JEeOaZ0o2E\nC82pQ8u8eiZjC5U98gh85zv2Z5061Z5/8EFljOiD6tRzzSYdHeKaWmBt9jd7/vnCGxh2xFBOVqzw\nNh3wy2TyH66qqpZHp075+6i9v6B79sCuXVYP7H/ctct+XpcuVhmR/diev6t8fdEWf5/4H92judmO\nPXu8861b4bHHLAh/7Wtw330WcN02jx0Lt91mo87f/hauuQZOP93SC50725+7utoeO3WyvnjgAViz\nBq6/Hi64oGW1yL77wn/8B1x9Ndx9N4wf7wX4vfZq/f2qq+0/gscft80fduzwjp07rZ3V1d7XuOdN\nTbBxox0bNrR8rKmBAQNaH/365a5s2bMH5s61fgpr2DDbD3TkSNuYev/9Wx59+nhtdn9f3XP3cPnP\n33vP/rPYs8eOpiZ7/OCD9gX1226z34H58+3vc/RoGDUKrrwSli6FP/4Rvv1ta+uYMXZ88Yv2vFDt\n+XdQW2t9WQpnA7/xPZ8M/CrrmidpuX3dbODoHN9rOTY7VYcOHTp0hD8K2ngoaKQeZjZp9jW1zmvZ\nQtx6ERGRYuoMNOBtZVdP7hulTznnxwJzS9U4EREp3ERsmYDl2KbT0HI2KViFzHKspDFX6kVERERE\nRJImzOSlSvUAVgX0hu+1PsBzwLvAs1gJaBoMBl4A3gSWAFOd19PYH3tj5b/12HpK7tIbaewLVzW2\naf2TzvO09sX7wOtYX8x3XktUX1RjaZkhQA25c/KVbCw2w9Yf1G8DvuecXwv8qNSNikl/4EjnvDuW\n0htOevujq/PYGbsPdQLp7QuA7wB/AJ5wnqe1L1ZgQdwvUX1xHPCM7/l1zpEmQ2gZ1N/Bm5zV33me\nRjOB8ag/ugILgC+Q3r6oxUqhT8Ybqae1L1YA+2W9VlBfFHtBL22F11o/vIlZa0nn7Nsh2CeYeaS3\nPzphn1zX4qWl0toXtwPfBZp9r6W1LzLYf3ALgcuc1wrqiygW9NoX+AtW+TIPG3H4Gyj5uZML0qQ7\n8BjwLWxDFb809Uczlo6qBU7ERql+aemL04F1WA4531zMtPQF2ETOo7CqwyuwFK5fYF9EsaDXDcAi\n4AjgQuAXvvci2wqvgqzFPkIBDMB+odOiBgvoD2HpF0h3fwBsBv4KjCSdfTEGWz9qBfAwcAr2+5HG\nvgBY4zyuxwbLoyiwL6JY0Gs49vER7ObXEGB/5/lCbPXGIdjkpXPxboSk1RPAFOd8Cl5wq3RVwP1Y\ntccdvtfT2B998SoY9gFOxUaqaeyLG7DB3sHAecDzwAWksy+6Aj2c827Aadj9uEj74hyC1365Bfi5\ncz4KC/7+NdVzTV5Ki4exfV13YfcWLsbubM8mIeVJJXQClnKoxwLYYuwTYBr740vYp9t6rHztu87r\naewLv5PwBn1p7IuDsd+Jeqzs142XBfVF0HpiZ2P/8NyE/WRslcarfNf0wFIubune54FvYL+snxk6\ndGimoSMLVouIpFMDBaydFZR+CZMT3wJcggX1C7HUy3utWtXQQCaT0ZHJMG3atNjbkJRDfaG+UF+0\nfQBDwwb0MEE9TE68l/Me2Ij+b2jTaREpAz/4ga1XX0mCgnoT8CCWE9+K3Zl9m5YLeh0HfATsAH6K\nlTWKiCRaUxPceqttvFFJwpQ0XgQcht2NHYBVu9zjHGDL7f4SW89iKHAzweu0p1pdXV3cTUgM9YVH\nfeEpRV98+KHtitWYa/eHMhZFSeMaoKdz3hPYiI3wJQ/94/WoLzzqC08p+sIN5pUW1KPYo/Q3WG3p\naqwS5uuRtU5EpEhWrWr5WCmCRuphpubegNVVDsSmPd+FV0AvIpJIjY22CXXaRuphShrHYBOQwOop\nV2A5+IXZ32z69OmfndfV1enjpojEprERjjgieUF9zpw5zJkzp91fHzT5qDNW+TIOS6/Mx9Z/edt3\nzc+x9StmYKuHvQqMADZlfa+MU3MpIhK7yZOhZ0949VWYl+CavaqqKgiO1Z8JU9J4JTALW7PjUVqX\nNN4KHIOt0jgbW8w9O6CLiCRKYyOMGpW8kXpHhSk9zPgOd73je3zvX4QtH9qM/Sfxe+Ap4OPIWiki\nErHGRhg5Etatgz17oLo67hZFI2hIX42lX8Zj+fUFtE6/+J0OfNu5PpvSLyKSCJkMdO9uterDhsGi\nRTBwYNytyi3q9EuYOnW/SdjKhCIiibV5s43Me/SAQYMqKwUTFNQL2Y6uK/BlbBMEEZHEWrXKgjlU\nXlAPyqkXki/5KvAP2silq6RRRJKgsRFqa+28tjZZE5A6WtIYRZ266zwCUi/+oC4iEpfGxuSO1LMH\nvDNmzCjo66NYehds+d0TgccL+ukiIjFIclDvqCiW3gW4Drs7uwCYE3krRUQiVMlBPSj94l961y1p\ndJfedfXGdgMfgaVm+kbeShGRCDU2wsSJdl5pQT2KksZJWMWLm2vfEGH7REQiV8kj9ShKGodhu12/\ngOXgL4isdSIiReAP6j172mSkTz6Jt01RiaKksQY4Glv0qyvwCjAXWJZ9oUoaRSRuO3fCRx/BAQfY\n86oqb7Tes2fbX1sKSShpXImlXLY7x4vAEQQEdRGROKxZA/36tVzrxQ3qw4fH1y5XEkoaHwdOwG6q\ndsV2RnqroFaIiJSIf+KRK2kTkDoiipLG/sDxzvsbgQ9QUBeRhPLn012VdLM0ipJGgOewskYRkUTL\nF9TfqpChaFSrNIZeFlJEJE6VPlKPoqQxg+1T+hq2OcbhkbVORCRilR7UoyhpXIRVxWwDJgIzgUM7\n2C4RkaJIe1APU9K4xXf+NPCf2GSkVvuUqk5dROLmX0vd1a8fbNwIu3dDTU087XJ1tE49KBfeGat8\nGQesBubTeju7fsA6bFQ/CvgjVgKZTdvZiUisMhnYZx/YtAm6dm353qBBMHcuDB6c+2vjEvV2dmFK\nGs8B3nCumQf8uqAWi4iUyMaNFsyzAzpUTq16UFD3lzR2AwbglTS6ZY13YTNIG4G/kmMmqYhIEuTK\np7sqJa8eVUnjVcCfgPVRNk5EJEoK6uFKGgdhgf5u57kS5yKSSArq4QL0HdjORxksma+JSCKSSGkI\n6lGUNI7E0jJgux5NxFI1rfYyVUmjiMSpsRGOOSb3e0kJ6kkoafR7EHgS+HOO91TSKCKxmjgRrrgC\nTj+99XtLl9rryxJW6lFoSWPQSL0JuBKYhVXC3I9X0gitF/YSEUmsMOmXTMY2zihXQUEdLFfuHs3O\na/5gfiZwo/NeM/BQlA0UEYlKrrXUXd27w157wccfw777lrZdUQpTp34nMAFbqOt8rE7dbzZWp34U\nVtN+b7RNFBHpuO3b4dNPoW/f/NcMGlT+E5CiqFP/1HfeHdvaTkQkUVavhgED2k6tJOVmaUdEUacO\ncBaWa38amBpN00REotNWPt1VCUE9iqV3wZbbnQmMxXLqh+W6SCWNIhKXcgnqHS1pjKJO3e/vzvfc\nD9uvtAV/UBcRKaVcS+5mGzQI6utL0558sge8M2bMKOjrg9IvC4Fh2FK6ewHn0npS0VC8GsqjncdW\nAV1EJE7lMlLvqDBL716JjcC3ArXYBtP+pXfPBv4JbPddN6IYjRURaa+0BPUwderPAjuxLeoagQW0\nnFV6GxbM3wI2Y+WP9wLHRt1YEZH2SktQDxqpQ7iyxlewgA62UUae8n4RkXi0NfHIdcABsHkz7NxZ\nmjYVQ5igHras0XUp8FRHGiUiEqXmZvjwQxg4sO3rOnWC/v2tpr1chV0mIKyTgUuA43O9qZJGEYnD\n+vXQsyd06RJ8rZuCOfjg4rcrl2Kv0giWG5+O5coBrsfWePlx1nUjsNUZJ2DpmmxapVFEYrFoEVxy\nSbhyxX/9VzjnHDj33OK3K4yoN56GcGWNB2IBfTK5A7qISGzC1Ki7yv1maZig3oStk74UK1dcg7f8\nrlvW+DPgIOBlrEJmfuQtFRFppzCVL65yD+phcurV2OqLh+GVNA6n5fK7/4alY84CPsKCvIhIIhQa\n1F99tbjtKaaoShrXY2ma3VE2TkTaZ8mS8l9CNkppGqkXo6RRRGK0ejWMG2dbs23fHndrkiFMjbqr\ntrbyg7pKVkTKRFMTTJoEV14Jw4fD1VfH3aJkKGSkPnCg/cdYrsV6YXLqha7UmJfq1EWKa8YM25Lt\nhhtsl59jjoGHH4bzz4+7ZfEqJKjvsw906wYbNsD++xe3XbmUok69M1b5Mg5YjVW2+Nd+8ZsObCH3\njVLVqYsU0bPPWi32okU23R2sLvvUU+Gll+DQQ+NtX1y2brXgvG1b+A2lR4yA3/8ejjyyuG0Loxh1\n6u5KjbOwRbsepXVJY38s73418H1s1cbuYRshIh2zejVMmQL/9V9eQAcLSjffDF//enrz6+4oPWxA\nh/K+WRomqE8Abneu/Q3wQ+f1e/DKGm8AdmAVMqdgk5G2RtnQStKRj1aVRn3haW9fNDVZeuWKKyBX\nRvPyy8svvx7l70UhqRdXJQf1auBOLLAfjqVdhmdd8xXgEGzW6eXA3RG3seIokHnUF5729sX06bam\nyfXX536/qgruuQeef97y6+VAQb39goJ6mBr1M4DfOefzgN5Av+iaKCL5zJoFv/2tpV2qq/Nf17Mn\n/PGPMHUqvPtuyZqXCGkL6kHVL7lq1EeHuKYWWJv9zW69tR0trEB//3uy+yKT8cq5sh9dbn6yqqrl\neaHy9YX/5xV6f93f5nztzyX7z9TWnyuTgV27bN3tHTu8Y+dOe71LFzv23ts7unSBmpr8/fTii3DL\nLeHbC3DXXTb69ufR83Hz61/7mpU95tLcDHv2WEon+8hk7D+OTp28R/e8qsrO3X7zn7f1e5HvvXy/\nF83NVtWzdWvLY8sWa2P37t7RrZs9vvQSnHdecP/41dbC7bfb30dbv0e5/h34tfX36L9+9GgYP76w\nNrbX2Vge3TUZ+FXWNU/Scqnd2Xh7lfotx2redejQoUNH+KOgRRKDRuphatSzr6l1Xst2SCENExGR\n6HUGGvCW3a0n941Sd6ejY4G5pWqciIgUbiI2+Wg5tkEGtKxRB6uQWQ68Ru7Ui4iIiIiIJM0E4B1g\nGXBtzG0ptQewKqA3fK/1AZ4D3gWexUpA02Aw8ALwJrAEmOq8nsb+2Bsr/63HZmm7E/rS2BeuamAx\nVngB6e2L94HXsb5wNxtKVF9UY2mZIUANuXPylWwscBQtg/ptwPec82uBH5W6UTHpD7graXTHUnrD\nSW9/dHUeO2P3oU4gvX0B8B3gD3hbZaa1L1ZgQdwvUX1xHPCM7/l1zpEmQ2gZ1N/Bm5zV33meRjOB\n8ag/umK7iX2B9PZFLVYKfTLeSD2tfbEC2C/rtYL6IszaLx2hDTZa64c3MWst6Zx9OwT7BDOP9PZH\nJ+yT61q8tFRa++J24LtAs++1tPZFBvsPbiFwmfNaQX0RdkGvtnLi+wJ/wSpf5mEjDn8DJT93ckGa\ndAceA76FLdPsl6b+aMbSUbXAidgo1S8tfXE6sA7LIeebe5qWvgCbyHkUVnV4BZbC9QvsiygW9LoB\nWAQcAVwI/ML3XmQbbFSQtdhHKIAB2C90WtRgAf0hLP0C6e4PgM3AX4GRpLMvxmDrR60AHsZWeX2I\ndPYFwBrncT02WB5FgX0RxYJew7GPj2A3v4YA7n4hC7HVG4dgk5fOxbsRklZPAFOc8yl4wa3SVQH3\nY9Ued/heT2N/9MWrYNgHOBUbqaaxL27ABnsHA+cBzwMXkM6+6Ar0cM67Aadh9+Mi7YtzCF775Rbg\n5875KCz4H+V7P9fkpbR4GNstahd2b+Fi7M72bBJSnlRCJ2Aph3osgC3GPgGmsT++hH26rcfK177r\nvJ7GvvA7CW/Ql8a+OBj7najHyn7deFlQXwStq3c29g/PTdhPxlZpvMp3TQ8s5eKW7n0e+Ab2y/qZ\noUOHZhoaGgJ+nIiIZGmggLWzgtIvYXLiW4BLsKB+IZZ6ea9VqxoayGQyOjIZpk2bFnsbknKoL9QX\n5dYX11yT4ZZbSvfzgKFhA3qYoB4mJ97LeQ9sRP83tJWdiFSoDz6wI6mCgnoT8CCWE9+K3ZnN3nT6\nOOAjbI/Sn2JljSIiFamx0Tb6TqowJY0XAYdhd2MHYNUu/k2njwV+ia1nMRS4meB12lOtLtfuwCml\nvvCoLzxJ7ovGxmRvdRd0o/Q4YBp2sxS8Kf7+tQe+CYzACuU/hy0LcGiO75Vx8kMiImWpudm2JezT\nB9a22rCzOKps37vQm0UGjdTDTPP/DTaLdDU2q/RbYX+4iEg5WbfONvHetMn2ok2ioDRJmKH1DVhd\nZR2WfnkOm12aPQWc6dOnf3ZeV1eX6I9YIiLZGhvhwAMtuH/4oZ1Hbc6cOcyZM6fdXx80pD8WmI6X\nfrkem0DyY981T2ETkF5ynv8/bI2YhVnfS+kXESlrTzwB995rQf0Xv4Djjiv+z4w6/RKmpPEdbAlV\nsNXDDiNHnbqISLlrbIRBg+xI6s3SKEoaP8YWuN8OfIBVyDS3+k4iImWuEoJ6mJLGG7EJSPtga8W8\ngAV6EZGK4gb1gQOTW6sexSqNfpOwRaxERCpOYyPU1pb3SL2QnYu6Al/G1ssWEak4q1YlP/0SRUmj\n66vAP1DqRUQqlJt+qa4u36BeyM5F5xGQelGduoiUq61bYfdu6N3bgvrq1ZDJQFXoYsNwil2n3hmr\nfBmHzRidj21p93bWdb2wMsZarAomF9Wpi0jZWroUTj8dli2zYN6jh43We/Uq7s+Nuk69CbgSmIVt\nQ/YorUsaAc5yrskX0EVEypqbegEbnSc1rx4U1MHbvTqDV3/uL2kEq08fjm3BNCfC9omIJII/qENy\ng3pQTr0auBObMdoILMBmlPrTL72Bu7DKl1XYproiIhUlV1BPYq16FHXqk7AyRvcG6oYI2ycikghu\njbpr4MBkjtSjqFMfhu12/QK2VswFkbVORCQh3Bp1V7mmX8KUq9QAR2MVMl2BV4C5wLLsC1XSKCLl\nKlf65fnno/85SVh691ps3ZfpzvP7sN2P/pT1vVTSKCJla9AgmDsXBjszd+bOhalTYf784v7cOJbe\nfRw4Abup2hUYjZU/iohUhKYmWL8e+vf3XivXnHqYpXf7A8c772/EyhsV1EWkYqxdC/vtBzU13msD\nBthmGU1N8bUrlzAljRdhS++6JY3u0rt+zwFnRN04EZEkyM6ngwX4/fazgJ/9XpyiWno34tUPRESS\nI1dQh2TWqkdR0pgBxgCvYfuVHh5Z60REEiC7Rt2VxLx6FCWNi7DVG7cBE4GZwKG5LlRJo4iUo7ZG\n6lEH9SSUNGZbAYwENmW9rpJGESlLF1wA48fDlCktX7/pJti+HW69tXg/O46Sxn6+HzjKOc8O6CIi\nZauScuphShrPAd5wrpkH/LooLRURiUm+oJ7EnHpQUPeXNHYDBuCVNLpljXcBR2Alj38lx/IAIiLl\nKpMpbU79TYuyAAAH30lEQVS9o6IqabwKWxZgfZSNExGJ2yef2KYYPXu2fq8cg3qYksZBWKC/23mu\nu6EiUjHyjdIB9t0Xdu2y/UuTIiiohwnQdwDXOddWoYlIIlJB8tWog43gBw5M1s3SoDr1RqwG3TUY\nbzMM10gsLQO269FELFWTXSWjOnURKTttjdTBS8EcmnN2TuGKXafeGatqGQesBuYD59NyOzu/B4En\ngT/neE916iJSdm6+GbZty1+Lfv758C//ApMnF+fnR12n3gRcCczCVl58lNYljSIiFSvMSD1J6Zeg\noA6WK3ePZuc1f0njmdi6L4uBEcDHEbdRRCQ2QUE9abXqYerU78SWCTgcS70Mz7pmNlanfhRW035v\ntE0UEYlP2Jx6UkRRp/6p77w7sCGqxomIxK3SgnqYOnWAs7Bc+9PA1GiaJiISr927YdMm6Ncv/zVJ\ny6lHsfQu2HK7M4GxwEPYsgKtqKRRRMrJmjUW0Kur818zYIBd19wMncLcpQyQxKV3G7C0zcas11XS\nKCJl5ZVX4OqrYe7ctq/r2xfefLPtEX17xbH07lDfDzzaecwO6CIiZWfVqnD7jyYprx62Tv3v2NK7\ntdgG0/469bOBfwLbfdeNKEZjRURKKegmqStJefWgnDrAs8BObIu6RmABLWeV3oYF87eAzViq5l4s\ndSMiUrbCBvUk1aqHSeuHKWt8BQvoYBtl5Fn+RkSkfBQyUi+noB62rNF1KfBURxolIpIE5RjUw6Rf\nCilZORm4BDg+15sqaRSRchJHTr3YJY0QvqxxBLY64wQsXZNNJY0iUjYyGejWDdavt8e2LF4MU6bA\n669H346oSxohXFnjgVhAn0zugC4iUlY++gi6dAkO6JCs9EuYoN6ErZO+FCtXXEPr5Xd/BhwEvIxV\nyMyPvKUiIiUUtkYdbPLR1q2wfXtx2xRGmJx6Nbb64mF4JY3D8ZbeBfg3LB1zFvARFuRFRMpW2Hw6\n2PIA7nIBn/tccdsV2JYQ14QpaVyPpWl2R9k4EZG4FBLUITm16sUoaRQRKXuFBvWk5NXD7nwkIpIq\n5RrUw+TUG4HBvueDsdF6wVSnLiJNTfDNb0JDA8ycCb17x92i3Bob4atfDX99VLXqpahT74xVvowD\nVmOVLf61X/ymA1vIfaNUdeoiKbdzJ0yaZJUiw4bBSy/BrFlwwAFxt6y1I4+EBx+Eo44Kd/0f/gBP\nPgmPPBJtO4pRpz4eq09/Fwvqj9K6pPE+7CbpD4Bp2KqN3cM2QkQq36efwhlnQFUVPPEE/OpXNhI+\n8URYuTL460utXNMvYTeeHgt0w9IuM5337nGOrwADgRpgDLZa44FYTbvk0JGPVpVGfeGp5L74+GM4\n7TSrEHnkEZvUU1UFN94Il10GY8fCsmXe9XH3xY4d8MknVn8eVrkE9TDljGcAv3PO5wG9gSLs/1E5\n4v6FTRL1hadS+2LdOjj5ZDjmGLj/fuicdSfvmmvg3/8d6uq8afZx98Xq1VZ3Xsj2dAMH2tfFnWUO\nulGaq5xxdIhraoG1HW6diJS1lSvh1FPh61+HGTNsdJ7LZZdBz5527eOPl7aNAGvXwquvwqJF9rhw\nof0nVIhu3WDvve0G8EEHQU1N8NdkMvapIJOBrl3b1/ZsUW08nf1XlfPrCrmTXMmWLrVfHFFf+JWq\nL9yRpH9EmWt06QZgfyDOF5TzWbzY9vi85prga889F3r0sLx7r14wf37udhTahrbs2gVLltj0/pEj\n4eij4bzz4Cc/ad/M0HHjYPRo2LzZAvy++1p1T+/eFvS3brW0ziefwJYt9lhdbf1zyy3R/Jmi2Hj6\n18AcLDUD8A5wEq1H6sux/UxFRCS8BuCQqL5ZZ+cbDsEqYOqxdV/8voK3KcaxQMC+2yIiEqeJWJ36\ncmykDi3LGcEqZJYDrwFHl7R1IiIiIiLSPhOwPPsy4NqY21JqD2D3Ft7wvdYHeA6bzPUsVgKaBoOB\nF4A3gSXAVOf1NPbH3lj5bz02r+OHzutp7AtXNbAYeNJ5nta+eB94HesLd1+KRPVFNZaWGYJNTsqV\nk69kY4GjaBnUbwO+55xfC/yo1I2KSX/gSOe8O5bSG056+8MtYOuM3Yc6gfT2BcB3gD/g7aqW1r5Y\ngQVxv0T1xXHAM77n1zlHmgyhZVB/B29yVn/neRrNxJagSHt/dMU2nvkC6e2LWmA2tnG9O1JPa1+s\nAPbLeq2gvihgvlS7aC321vrhlXuuJZ2zb4dgn2Dmkd7+6IR9cl2Ll5ZKa1/cDnwXK5d2pbUvMth/\ncAuBy5zXCuqLMEvvdoSWZWxbhvT1UXfgMeBb2Iqefmnqj2YsHdULmIWNUv3S0henA+uwHHJdnmvS\n0hcAx2P7QO+P5dGzR+WBfVHskXpka7FXkLXYRyiAAdgvdFrUYAH9IbyF4dLcHwCbgb8CI0lnX4zB\n1o9aATwMnIL9fqSxL8ACOtgWoX/B1t8qqC+KHdQXAsPwJi+di3cjJK2eAKY451PwglulqwLux6o9\n7vC9nsb+6ItXwbAPcCo2Uk1jX9yADfYOBs4DngcuIJ190RXo4Zx3A07D7sclri9yTV5Ki4exNeh3\nYfcWLsbubM8mIeVJJXQClnKoxwLYYqzcNY398SVgEdYXr2P5ZEhnX/idhDfoS2NfHIz9TtRjZb9u\nvExjX4iIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIhI1P4/IvDIeiW0M/cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74eb21be90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = gate_fn(input, i_s,  i_w, i_t, q, q_w, 0)\n",
    "\n",
    "for i in xrange(ep_pass):\n",
    "    plt.subplot(ep_pass, 1, i+1)\n",
    "    plt.plot(np.arange(len(g[ep_pass-i-1])), g[ep_pass-i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
