from common.utils import *
import theano
import theano.tensor as T
import numpy
from head import *
from controller import ControllerFeedforward
import scipy


def cosine_sim(k, M):
    """
    :type k: tensor variable with size (batch_size, mem_width)
    :param k: input to calculate similarity

    :type M: tensor variable with size (mem_size, mem_width)
    :param M: memory matrix

    :return: similarity measure with size (batch_size, mem_size)
    """
    k_lengths = T.sqrt(T.sum(k ** 2, axis=1)).dimshuffle((0, 'x'))
    k_unit = k / (k_lengths + 1e-5)

    M_lengths = T.sqrt(T.sum(M ** 2, axis=1)).dimshuffle((0, 'x'))
    M_unit = M / (M_lengths + 1e-5)
    return T.dot(k_unit, T.transpose(M_unit))


controller_size = 100
mem_size = 128
mem_width = 20
similarity = cosine_sim
shift_width = 3
num_heads = 1

# since X, M, W_read and W_write are changing through time
# we firstly try to write their step-wise function
x_t = T.matrix('x_t')  # current input
m_t = T.matrix('m_t')
w_read_t = T.matrix('w_read_t')
w_write_t = T.matrix('w_write_t')


""" shift_conv is with size (shift_width, mem_size)
    each row represents a shift, one of +1, 0, -1
    suppose shift_width = 3, then the operations'
    order of the rows of shift_conv are +1, 0, -1

    scipy.linalg.circulant receives a vector with size (N, )
    and returns a matrix with size (N, N)
    each column is generated by applying the +1 operation on
    the previous column, and the first column is the input
"""
# convolutions applied to the 'w' generated by heads
shift_conv = scipy.linalg.circulant(numpy.arange(mem_size)).T[
    numpy.arange(-(shift_width // 2), (shift_width // 2) + 1)
][::-1]

# Below are the body of the step-wise function











